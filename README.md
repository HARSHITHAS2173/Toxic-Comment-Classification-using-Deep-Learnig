Comment Toxicity Model using Deep Learning

The goal of this project is to develop a deep learning model that can automatically detect and classify toxic comments in online comments. Toxic comments include those that are disrespectful,inflammatory,or offensive in nature. By identifying and flagging these comments, online platforms can improve the quality of discussions and create safer environments for users. We also find the toxicity score and classes to which a comment belongs which helps us in identifying how provocative a comment is.

